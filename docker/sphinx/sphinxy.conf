#
# Sphinx configuration file sample
#
# WARNING! While this sample file mentions all available options,
# it contains (very) short helper descriptions only. Please refer to
# doc/sphinx.html for details.
#

#############################################################################
## data source definition
#############################################################################

source blog_src
{
	type			= mysql

	sql_host		= db
	sql_user		= homestead
	sql_pass		= secret
	sql_db			= homestead
	sql_port		= 3306	# optional, default is 3306

	sql_query_pre		= SET NAMES utf8

    sql_query		= \
	    	SELECT publications.id, publications.title, publications.heading, \
	    	publications.annotation, publications.text \
	    	FROM publications


	sql_ranged_throttle	= 0


}


index blog_index
{
        source                  = blog_src

        path                    = /var/lib/sphinx/data/blog

        docinfo                 = extern

        dict                    = keywords

        mlock                   = 0

        morphology              = stem_enru

        min_stemming_len        = 3

        min_word_len            = 3

        min_prefix_len                = 3

        expand_keywords               = 1

        html_strip              = 1

        index_exact_words     = 1

}

#############################################################################
## searchd settings
#############################################################################

searchd
{

        listen                  = 9312
        listen                  = 9306:mysql41

        # log file, searchd run info is logged here
        # optional, default is 'searchd.log'
        log                     = /var/lib/sphinx/log/searchd.log

        # query log file, all search queries are logged here
        # optional, default is empty (do not log queries)
        query_log               = /var/lib/sphinx/log/query.log

        # client read timeout, seconds
        # optional, default is 5
        read_timeout            = 5

        # request timeout, seconds
        # optional, default is 5 minutes
        client_timeout          = 300

        # maximum amount of children to fork (concurrent searches to run)
        # optional, default is 0 (unlimited)
        max_children            = 30

        # maximum amount of persistent connections from this master to each agent host
        # optional, but necessary if you use agent_persistent. It is reasonable to set the value
        # as max_children, or less on the agent's hosts.
        persistent_connections_limit    = 30

        # PID file, searchd process ID file name
        # mandatory
        pid_file                = /var/lib/sphinx/log/searchd.pid

        # seamless rotate, prevents rotate stalls if precaching huge datasets
        # optional, default is 1
        seamless_rotate         = 1

        # whether to forcibly preopen all indexes on startup
        # optional, default is 1 (preopen everything)
        preopen_indexes         = 1

        # whether to unlink .old index copies on succesful rotation.
        # optional, default is 1 (do unlink)
        unlink_old              = 1

        # attribute updates periodic flush timeout, seconds
        # updates will be automatically dumped to disk this frequently
        # optional, default is 0 (disable periodic flush)
        #
        # attr_flush_period     = 900


        # MVA updates pool size
        # shared between all instances of searchd, disables attr flushes!
        # optional, default size is 1M
        mva_updates_pool        = 1M

        # max allowed network packet size
        # limits both query packets from clients, and responses from agents
        # optional, default size is 8M
        max_packet_size         = 8M

        # max allowed per-query filter count
        # optional, default is 256
        max_filters             = 256

        # max allowed per-filter values count
        # optional, default is 4096
        max_filter_values       = 4096

        max_batch_queries       = 32

        workers                 = threads
        # for RT to work

}

common
{

}


